{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias, Variance & Noise\n",
    "\n",
    "Error is equal to Bias squared plus Variance plus irreductible error.  \n",
    "  \n",
    "$\\large Y = f(X) + \\varepsilon $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large Err = E[(Y - \\hat{f}(X))^2] = [Y - E[\\hat{f}(X)]]^2 + E[\\hat{f}(X) - E[\\hat{f}(X)]]^2 + \\varepsilon $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![](biasvariance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate MSE\n",
    "\n",
    "$\\large \\frac{1}{M} \\sum_{i=1}^M (y_i-\\hat{y_i})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(yh):\n",
    "    y_ = [y] * nSim\n",
    "    m = np.mean((y_ - yh)**2)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Bias\n",
    "$\\large (\\frac{1}{M} \\sum_{i=1}^M \\hat{y_i}) - y_i $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bias(yh):\n",
    "    bias = np.mean(yh) - y\n",
    "    return bias\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Variance\n",
    "$\\large \\mu = \\frac{1}{M} \\sum_{i=1}^M \\hat{y_i}) $  \n",
    "  \n",
    "$\\large \\frac{1}{M} \\sum_{i=1}^M (\\hat{y_i} - \\mu)^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_var(yh):\n",
    "    var = np.mean((yh - np.mean(yh))**2)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_population():\n",
    "    size=5000\n",
    "    x1 = np.random.rand(size)\n",
    "    x2 = np.random.rand(size)\n",
    "    x3 = np.random.rand(size)\n",
    "    x4 = np.random.rand(size)\n",
    "    x5 = np.random.rand(size)\n",
    "    \n",
    "    b0= 1.1; b1=2.2; b2 = 3.3; b3= 4.4; b4=5.5; b5= 6.6\n",
    "    y = b0 + b1*x1 + b2*(x2**2) + b3*(x3*x4) + b4*x4 + b5*x5 \n",
    "    random_state=1234\n",
    "    r = np.random.RandomState(random_state)\n",
    "    noise = r.normal(-5, 10, size)\n",
    "    y = y + noise\n",
    "    df = pd.DataFrame({'target':y, 'X1':x1, 'X2':x2, 'X3':x3, 'X4':x4, 'X5':x5})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(lm, dt):\n",
    "    Pred = []\n",
    "    for i in range(0, nSim):\n",
    "        D = get_population()\n",
    "        X = D[['X1', 'X2', 'X3', 'X4', 'X5']]\n",
    "        Y = D['target']\n",
    "        lm.fit(X,Y)\n",
    "        dt.fit(X,Y)\n",
    "        pred = (i, lm.predict(pd.DataFrame(X_test).T), dt.predict(pd.DataFrame(X_test).T))\n",
    "        Pred.append(pred)\n",
    "    return pd.DataFrame(Pred)\n",
    "\n",
    "def evaluate(pred):\n",
    "    mse_lm = calc_mse(pred[1])[0]\n",
    "    bias_lm = (calc_bias(pred[1])[0])**2\n",
    "    var_lm = calc_var(pred[1])[0]\n",
    "    mse_dt = calc_mse(pred[2])[0]\n",
    "    bias_dt = (calc_bias(pred[2])[0])**2\n",
    "    var_dt = calc_var(pred[2])[0]\n",
    "    print('Mod\\t Mse\\t Bias\\t Var')\n",
    "    print('LM\\t',\"{0:.1f}\".format(mse_lm), '\\t', \"{0:.1f}\".format(bias_lm), '\\t', \"{0:.1f}\".format(var_lm))\n",
    "    print('DT\\t',\"{0:.1f}\".format(mse_dt), '\\t', \"{0:.1f}\".format(bias_dt), '\\t', \"{0:.1f}\".format(var_dt))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Depth:  3 \n",
      "\n",
      "Mod\t Mse\t Bias\t Var\n",
      "LM\t 86.5 \t 86.5 \t 0.1\n",
      "DT\t 79.0 \t 77.4 \t 1.6\n",
      "\n",
      " Depth:  4 \n",
      "\n",
      "Mod\t Mse\t Bias\t Var\n",
      "LM\t 86.4 \t 86.3 \t 0.1\n",
      "DT\t 81.2 \t 78.3 \t 2.9\n",
      "\n",
      " Depth:  6 \n",
      "\n",
      "Mod\t Mse\t Bias\t Var\n",
      "LM\t 86.1 \t 86.0 \t 0.1\n",
      "DT\t 90.3 \t 86.8 \t 3.5\n",
      "\n",
      " Depth:  8 \n",
      "\n",
      "Mod\t Mse\t Bias\t Var\n",
      "LM\t 86.3 \t 86.2 \t 0.1\n",
      "DT\t 101.2 \t 89.6 \t 11.6\n",
      "\n",
      " Depth:  9 \n",
      "\n",
      "Mod\t Mse\t Bias\t Var\n",
      "LM\t 85.9 \t 85.9 \t 0.1\n",
      "DT\t 108.3 \t 92.2 \t 16.1\n",
      "\n",
      " Depth:  10 \n",
      "\n",
      "Mod\t Mse\t Bias\t Var\n",
      "LM\t 86.7 \t 86.7 \t 0.1\n",
      "DT\t 101.1 \t 84.6 \t 16.5\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(22)\n",
    "X_test = np.random.rand(5)\n",
    "y = get_population()['target'][0]\n",
    "   \n",
    "nSim = 100\n",
    "for dt_depth in [3,4,6,8,9,10]:\n",
    "    print(\"\\n Depth: \", dt_depth, '\\n')\n",
    "    lm = linear_model.LinearRegression()\n",
    "    dt = DecisionTreeRegressor(max_depth = dt_depth)\n",
    "    \n",
    "    result = calculate(lm, dt)\n",
    "    evaluate(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits & Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/end-your-bias-about-bias-and-variance-67b16f0eb1e6\n",
    "https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229\n",
    "https://www3.nd.edu/~rwilliam/stats1/x12.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
