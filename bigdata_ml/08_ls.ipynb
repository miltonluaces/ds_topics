{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Mllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkContext(appName=\"Pspark mllib Example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=1, product=1, rating=5.0),\n",
       " Rating(user=1, product=2, rating=1.0),\n",
       " Rating(user=1, product=3, rating=5.0),\n",
       " Rating(user=1, product=4, rating=1.0),\n",
       " Rating(user=2, product=1, rating=5.0),\n",
       " Rating(user=2, product=2, rating=1.0),\n",
       " Rating(user=2, product=3, rating=5.0),\n",
       " Rating(user=2, product=4, rating=1.0),\n",
       " Rating(user=3, product=1, rating=1.0),\n",
       " Rating(user=3, product=2, rating=5.0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = spark.textFile('D:/data/csv/sparkmllib_test.csv')\n",
    "ds_rdd = ds.map(lambda l: l.split(',')).map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n",
    "ds_rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build & train model\n",
    "Build the recommendation model using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 10\n",
    "epochs = 10\n",
    "model = ALS.train(ds_rdd, rank, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (3, 1),\n",
       " (3, 2)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = ds_rdd.map(lambda p: (p[0], p[1]))\n",
    "test_ds.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 1), 4.996853911927506),\n",
       " ((1, 2), 1.0005066589656035),\n",
       " ((1, 3), 4.996853911927506),\n",
       " ((1, 4), 1.0005066589656035),\n",
       " ((2, 1), 4.996853911927506),\n",
       " ((2, 2), 1.0005066589656035),\n",
       " ((2, 3), 4.996853911927506),\n",
       " ((2, 4), 1.0005066589656035),\n",
       " ((3, 1), 1.0004866575445481),\n",
       " ((3, 2), 4.996953923842356)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_pred = model.predictAll(test_ds).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "test_ds_pred.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((2, 2), (1.0, 1.0005066589656035)),\n",
       " ((1, 2), (1.0, 1.0005066589656035)),\n",
       " ((1, 4), (1.0, 1.0005066589656035)),\n",
       " ((3, 4), (5.0, 4.996953923842356)),\n",
       " ((2, 4), (1.0, 1.0005066589656035)),\n",
       " ((4, 2), (5.0, 4.996953923842356)),\n",
       " ((4, 3), (1.0, 1.0004866575445481)),\n",
       " ((2, 1), (5.0, 4.996853911927506)),\n",
       " ((4, 1), (1.0, 1.0004866575445481)),\n",
       " ((3, 1), (1.0, 1.0004866575445481))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_valid = ds_rdd.map(lambda r: ((r[0], r[1]), r[2])).join(test_ds_pred)\n",
    "test_ds_valid.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  6.5692100820873525e-06\n"
     ]
    }
   ],
   "source": [
    "mse = test_ds_valid.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"MSE = \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'D:/data/model/spmllib1'\n",
    "model.save(sc, model_file)\n",
    "sameModel = MatrixFactorizationModel.load(sc, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits & Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tutorialspoint.com/pyspark/pyspark_mllib.htm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitc33de82c9da04edea88eb124459bf44a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
